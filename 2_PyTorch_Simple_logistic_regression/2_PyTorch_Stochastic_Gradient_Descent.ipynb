{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fk5tI_CFpeS3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training with Stochastic gradient descent\n",
        "\n",
        "## Gradient Descent Algorithm\n",
        "\n",
        "```py\n",
        "For each training epoch:\n",
        "  overall_loss L = 0\n",
        "  For each training example:\n",
        "    output = model_call(z)\n",
        "    overall_loss L = overall_loss L + l(output, label) # l() is the loss function\n",
        "\n",
        "    overall_loss L = overall_loss L/n # this is normalization, n is no of training example, for reasonable scale and easier comparisions.\n",
        "    # till here we computed the overall loss\n",
        "    # Now using this loss to compute gradient of loss with respect to parameters of the network in our case its w and b\n",
        "    # once we get these gradients then we use these to update the parameters.\n",
        "    w = w - lr*gradient_of_loss_wrt_w\n",
        "    b = b - lr*gradient_of_loss_wrt_b\n",
        "    # here we are multiplying gradient with lr learning rate(alpha) which is small value that scales the loss so that our updates are not too large.\n",
        "    # large updates might disturb the training\n",
        "    # alpha is a hyper parameter.\n",
        "    # and tuning this for finding the right value for alpha\n",
        "```\n",
        "\n",
        "**Notes**\n",
        "\n",
        "Gradient descent computes the loss over whole trainig epoch. and epoch meaning doing forward pass one single time on whole dataset that is one epoch. and other thing is that loss is based on whole training epoch the parameter update will be also on once per epoch.\n",
        "\n",
        "## Stochastic Gradient Descant\n",
        "\n",
        "Stochastic gradient descant is the flawor  of gradient descent with more frequent updates.\n",
        "\n",
        "**Stochastic gradient descant algorithm**\n",
        "```py\n",
        "For each training epoch:\n",
        "  For each training example:\n",
        "    output = model_call(z)\n",
        "    L = loss_function(output, label)\n",
        "\n",
        "    Compute gradients of parameters & update parameters\n",
        "    w = w - lr*gradient_of_loss_wrt_w\n",
        "    b = b - lr*gradient_of_loss_wrt_b\n",
        "```\n",
        "\n",
        "- Its similar to previous method iterating for multiple training epochs, in each training epoch iterate over each training example.\n",
        "- then compute the output from the model\n",
        "- then compute the loss, in gradient descent we kept updating the loss for whole training epoch before we compute the gradients.\n",
        "- **In contrast here, stochastic gradient descent we compute the gradient of the loss for single training example**\n",
        "- and using this loss we update the model parameters for single training example.\n",
        "- In conclusion, we are **updating model after each training example**.\n",
        "- So here difference is that we have more frequent updates when we iterate over the dataset.\n",
        "- ðŸŸ¥ However, updating the model parameter after each training examples is also not ideal. because loss is an approximation of the overall loss, and for using just one training example we can get prety rough approximations.\n",
        "\n",
        "To improve the rough approximation and use concept of linear algebra to speedup the training theres a concept called **mini batch gradient descent** which is flawor of stochastic gradient descent\n",
        "\n",
        "**Stochastic Gradient Descent With Mini Batch**\n",
        "\n",
        "Mini batch gradient descent is hybrid of gradient descent and stochastic gradient descant algorithm.\n",
        "\n",
        "**GD**: 1 update per epoch\n",
        "\n",
        "**SGD**: n updates per epoch where n is total no of training example.\n",
        "\n",
        "**MGD(Mini batch GD)**:\n",
        "- its hybrid between GD and SGD.\n",
        "- here we form small groups or batches of the training examples and will make 1 update after each batch.\n",
        "- what will be the optimal size of small mini batches? so `mini batch sizes are tuning parameter`, typical minibatch sizes are power of 2. 2^2 = 4 etc. and this hase something to do with GPU architectures, bcs of using our hardwares efficiently\n",
        "\n",
        "```py\n",
        "For each training epoch:\n",
        "  For each minibatch: # new, iterating over mini batches\n",
        "    overall_loss L = 0\n",
        "\n",
        "    For each training example in minibatch:\n",
        "      output = model_call(z)\n",
        "      overall_loss L = overall_loss L + loss_funct(output, label)\n",
        "    overall_loss L = overall_loss L / n\n",
        "    Compute gradients of parameters & update parameters per batch\n",
        "    w = w - lr*gradient_of_loss_wrt_w\n",
        "    b = b - lr*gradient_of_loss_wrt_b\n",
        "```\n",
        "\n",
        "## Advantages of Mini Batch GD\n",
        "\n",
        "- The gradients from these mini batches are un biased estimates of the gradient, that's because they don't systematically deviate from the calculation of the gradients on the whole dataset.\n",
        "- Updates will be less noisy\n",
        "- faster than GD because more than 1 updates per epoch. model will learn more faster.\n",
        "- much better GPU utilization and it lets us take advantage of certain concepts of linear algebra(matrix multiplication) than the SGD because here we can pass multiple training example to the model which can use matrix multiplication to compute instead of passing single single trainig examples for more see tensor notebook.\n",
        "\n",
        "# Hyper tuning parameters in GD\n",
        "- learning rate\n",
        "- mini batch size\n"
      ],
      "metadata": {
        "id": "21Z8FimF8X8C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KP2ADlnzrupv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate gradient using PyTorch\n"
      ],
      "metadata": {
        "id": "usA7qM4zSW8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Parameters\n",
        "w_1 = torch.tensor([0.23], requires_grad=True) # initializing model parameters, requires_grad = True meaning we want gradient of loss wrt these parameters\n",
        "b = torch.tensor([0.1], requires_grad=True)\n"
      ],
      "metadata": {
        "id": "GjnRUthvSc4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input and true label\n",
        "x_1 = torch.tensor([1.23])\n",
        "y = torch.tensor([1.])"
      ],
      "metadata": {
        "id": "xEaU6hhVTLgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the weighted sum\n",
        "u = x_1 * w_1 # weighted sum\n",
        "z = u + b # add bias\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTUW8J26Tdaj",
        "outputId": "df3a88d9-932d-42d5-8047-ab70e600e21a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3829], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.sigmoid(z)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyT2FupcTq79",
        "outputId": "78b72635-9662-47d9-dbcf-140a36eb1be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5946], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = F.binary_cross_entropy(a, y) # calculate the loss\n",
        "print(\"loss:\", l)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lR5FHMMT3bH",
        "outputId": "c4c77bc0-1d24-4adf-f431-4713759b15f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: tensor(0.5199, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we want to compute gradient of the loss, compute the partial derivatives wrt w1 and b\n",
        "# we can compute partial derivative using PyTorch's autograd engine\n",
        "from torch.autograd import grad\n",
        "\n",
        "grad_L_w1 = grad(l, w_1, retain_graph=True) # computing gradients automatically\n",
        "# retain graph True meaning keep computing graph in memory otherwise it will deconstruct the graph that we previously build, and also for computing for bias b\n",
        "grad_L_w1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efVAgQJoUQ9u",
        "outputId": "f1a7813c-84dc-4934-90c8-7a47fca9f526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.4987]),)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad_L_b = grad(l, b, retain_graph=True)\n",
        "grad_L_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp4kWwC5VaNV",
        "outputId": "758e8a3b-a64a-493e-f150-08b8298bfcdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.4054]),)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## .backward() method\n",
        "Instead of using graph and grad function manually, we can compute partial derivative of model parameters with only one .backward() call.\n"
      ],
      "metadata": {
        "id": "wpHKeu2jVqjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l.backward()"
      ],
      "metadata": {
        "id": "qih98HXZVkdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w_1.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SZZeR62V8_N",
        "outputId": "b0e3f660-93f6-47d7-cffd-13894da735a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4987])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iqsf6kq4V_Lg",
        "outputId": "4140f738-95b0-4059-ba3a-c80d15dd2eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4054])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0BjKzuxcWAhI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}