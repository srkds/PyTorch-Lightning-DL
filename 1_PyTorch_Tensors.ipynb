{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch\n",
        "\n",
        "## What is PyTorch?\n",
        "\n",
        "Its 3 things\n",
        "- Tensor library\n",
        "- Automatic differentiation engine\n",
        "- Deep learning library\n",
        "\n",
        "Its `free` and `open source`\n",
        "\n",
        "### History of PyTorch\n",
        "- `PyTorch` is based on `torch` which is another popular library written in `lua` programming language.\n",
        "- Because of most people love python and don't want to learn lua, PyTorch originated from torch.\n",
        "- making it available in python based on torch7\n",
        "- happend in 2016\n",
        "- Most likely used deep learning library for researchers\n",
        "\n",
        "### Tensors\n",
        "Mathematically: It is generalization of vectors, matrices, etc.\n",
        "\n",
        "Computationally: as a data container for storing multi dimentional arrays\n",
        "\n",
        "### 1. Scalar (Rank - 0 Tensor)\n",
        "- In `python` its number\n",
        "- Can think of it as float\n",
        "```py\n",
        "a = 10.\n",
        "print(a)  //10.\n",
        "```"
      ],
      "metadata": {
        "id": "ltc9bNdSPLZr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0XBbI62O0Zv",
        "outputId": "16902aeb-7cc4-48e8-fb6a-9534714bf0b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.0\n"
          ]
        }
      ],
      "source": [
        "a = 10.\n",
        "print(a) # think of it as a float"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Equivalent in `PyTorch`\n"
      ],
      "metadata": {
        "id": "bUg_519N7nUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor(10.)\n",
        "a # scalar tensor or rank-0 tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JExr0s0J7c8d",
        "outputId": "04b72cfe-65c0-47b3-b1b5-dbf220bed8c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10.)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can use a.shape to check dimentionality or rank of a Tensor\n",
        "a.shape\n",
        "\n",
        "\"\"\"\n",
        "It returns nothing because its Rank-0 tensor.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QDxIw0qH8fdU",
        "outputId": "7216e3f4-14b3-4f3b-c2c5-4f5d8676e5a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nIt returns nothing because its Rank-0 tensor.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Vectors (Rank-1 Tensor)\n",
        "- In Python, we can think simple list as a vector/ Rank-1 tensor\n"
      ],
      "metadata": {
        "id": "Cesrl2Sk9BZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1., 2., 3.]\n",
        "a # Vector: simple list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otM4L5uf8y7Q",
        "outputId": "ee66ec67-1e4d-4bf0-8253-a415c3d7c083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 2.0, 3.0]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In PyTorch, its same as before but wrapping the list to the `torch.tensor`\n"
      ],
      "metadata": {
        "id": "7xr_yscm-Gtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1., 2., 3.])\n",
        "a # Vactor/Rank-1 Tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeHfIXIT9tEv",
        "outputId": "f1b19fbc-673d-4a0d-d56a-c92781249f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape # will return 3\n",
        "# because its 3 element tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ5ETZCl-ZL-",
        "outputId": "836f7e86-4441-406b-d3ab-0a8da26e3b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Matrices (Rank-2 Tensor)\n",
        "- Here we use list of lists.\n",
        "- This list has two sub list, and each of the sub list represents the row, So this will result in a matrix consisting of 2 rows and 3 columns.\n",
        "- We can think of the rows as a `training example`, and columns represnts the `features` of the dataset"
      ],
      "metadata": {
        "id": "DUEvN1ja-zEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1., 2., 3.],\n",
        "                  [4., 5., 6.]])\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9dCyKPf-qdV",
        "outputId": "45a54fc0-52f8-4e4a-cf17-4840f7fbcb65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6RMiZNv_Q7N",
        "outputId": "cf2883f3-d8e5-48b0-d29b-3d8341b4a8a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Considering realworld dataset\n",
        "- We can think image as a matrix\n",
        "\n",
        "<img src=\"https://images.pexels.com/photos/539694/pexels-photo-539694.jpeg\" width=\"400\" >\n",
        "\n",
        "- Where the rows and the columns represents the pixels of the image.\n",
        "- Here the image refers to 1 training example\n",
        "\n",
        "**Look at RGB image**\n",
        "\n",
        "Red, green, blue, 3 different color channels\n",
        "\n",
        "- So, in above image we have 3 color channels rgb.\n",
        "- we can think of this as a `stack of matrices`.\n",
        "- each layer/color channel represents the matrix.\n",
        "- as we already know scalar(rank-0 tensor), vectors(rank-1 tensor), and matrices(rank-2 tensors).\n",
        "\n",
        "### 4. 3D-tensors\n",
        "- So we this 3 dimentional data we call it **3D-tensor**\n",
        "- We can think stack of matrices as a 3D tensors\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aHwmLEHpVYI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[[1., 2., 3.],[2., 3., 4.]],\n",
        "                  [[4., 5., 6.], [7., 8., 9.]]])\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcRhdyW7_SfU",
        "outputId": "9a90fc85-a0a1-4b75-eec5-bb23a91d86e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 2., 3.],\n",
              "         [2., 3., 4.]],\n",
              "\n",
              "        [[4., 5., 6.],\n",
              "         [7., 8., 9.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "So, when we use a.shape it returns 3 numbers\n",
        "- each number represents one dimention or one rank,\n",
        "- and then numbers represents the values in this dimention\n",
        "\"\"\"\n",
        "a.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfK5GNVrbALh",
        "outputId": "7260d5ca-4dc9-4064-fb3d-ffaedec2f7c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. 4D(rank-4)tensor\n",
        "\n",
        "Going 1 step further we can also have a stack of multiple color images.\n",
        "\n",
        "this would add another dimention.\n",
        "\n",
        "And in this case we have 4 dimentional tensor or rank-4 tensor"
      ],
      "metadata": {
        "id": "GatqeFvcd5eH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.stack((a, a))\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g7TqJdcbQ72",
        "outputId": "26dbbd30-a854-41be-bf02-f003ccce821d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1., 2., 3.],\n",
              "          [2., 3., 4.]],\n",
              "\n",
              "         [[4., 5., 6.],\n",
              "          [7., 8., 9.]]],\n",
              "\n",
              "\n",
              "        [[[1., 2., 3.],\n",
              "          [2., 3., 4.]],\n",
              "\n",
              "         [[4., 5., 6.],\n",
              "          [7., 8., 9.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xQLLJwngIMf",
        "outputId": "df5285ad-3bcb-4c33-88b5-d5d6ab522f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So it looks similar like numpy's array, now let's see how tensor is different than a numpy array.\n"
      ],
      "metadata": {
        "id": "8Dn6kBzQgWDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing Tensor library with Array library\n",
        "\n",
        "- they are actually the same thing.\n",
        "- tensor library = array library\n",
        "- torch.tensor ~= numpy.array: torch.tensor is almost identical to numpy.array\n",
        "\n",
        "Difference\n",
        "\n",
        "|torch.tensor|\n",
        "|:-|\n",
        "|+ supports GPU computation|\n",
        "|+ Automatic differentiation support, very useful when training neural nets|\n",
        "\n",
        "### How tensors and arrays differe from regular python lists?\n",
        "\n",
        "**Python Lists**\n",
        "+ **Pros:** Can store heterogeous types (mix str, float, etc). you can store float, strings, and other objects mixed in a list.\n",
        "+ **Pros:** In python list we can easily remove or add items using `.append` or `.pop`\n",
        "+ **Cons:** while lists are easy to use and flexible, lists are very slow when it comes to numerical computation(that is the main motivation behind tensors)\n",
        "\n",
        "**Tensors**\n",
        "- Limitations of using tensors though is that all elements in tensors have to be the same type(eg. float, integer)\n",
        "- In contrast to lists, tensors also have a fixed size, so we can't easily add or remove If we want to have a larger tensor, we have to create new empty tensor with a larger size and copy over the all the elements and add the new elements to it\n",
        "\n",
        "this sounds like tensors are bad, However tensors have certain advantages over the lists which are extreamly useful for deep learning, which is heavily based on numerical computations.\n",
        "\n",
        "- tensors support wide variety of different computations.\n",
        "- numerical computations are fast"
      ],
      "metadata": {
        "id": "y0UMOFqZ49uJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Tensors In PyTorch\n",
        "\n",
        "1. `torch.tensor()`: Creating Tensors\n",
        "    - its most fundamental function. bcs that's how we create a tensors in PyTorch"
      ],
      "metadata": {
        "id": "e7XJ0SC6I9zK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1., 2., 3.])\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54hdqrdagJYm",
        "outputId": "7a3effaa-343c-4a1d-9bfb-36b67c66078a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. `.shape` Checking Shape of Tensors\n",
        "    - tensor.shape to check the shape of the tensor.\n",
        "    - using `.shape` attribute we can check the no of elements in the tensor.\n",
        "    - in 2D tensor 1st no referes no of rows in tensor, and 2nd no referes no of columns in tensor.\n",
        "    - to check rank of the tensor count the no of no that are returned by `.shape`"
      ],
      "metadata": {
        "id": "4RiRWL7pJl_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1., 2., 3.], [3., 4., 5.]])\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBrXSvpeJkSS",
        "outputId": "3a71bcda-5101-402f-f646-e8770ba34e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [3., 4., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.shape # will get [2,3] tow numbers meaning its 2D tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lIrwXutLCGB",
        "outputId": "79fb22d1-d9f8-496b-ce72-80a4d626304c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. `.ndim`: Checking the Rank/ Number of Dimentions\n",
        "    - use .ndim to check rank or dimention of the tensor"
      ],
      "metadata": {
        "id": "0F85ZAzXLNu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[[1., 2., 3.], [4., 5., 6.]], [[3., 4., 5.], [6., 7., 8.]]])\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwwDi5AyLK0w",
        "outputId": "641125d6-d155-4f75-9df8-de07b0be0f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 2., 3.],\n",
              "         [4., 5., 6.]],\n",
              "\n",
              "        [[3., 4., 5.],\n",
              "         [6., 7., 8.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.ndim # will get dimention of the tensor, in our case its 3D tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzMO-VUmL0_d",
        "outputId": "2f2816d7-38be-4264-bd0d-9f04d4d0223a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. `.dtype`: Checking the Data type of Tensor\n",
        "    - as tensor can only store same type of data.\n",
        "    - we can see the datatype of the tensor.\n",
        "    - below it returns torch.float32, meaning 32 bit precision\n",
        "    - that's prefered precision in deep learning bcs of efficiency reasons"
      ],
      "metadata": {
        "id": "NlZoYESVMFVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1., 2., 3.], [5., 6., 7.]])\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SClvJKvNL1yv",
        "outputId": "5520e105-cd03-4f48-be69-a822d2dde56d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [5., 6., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.dtype # will get data type of tensor that is float32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0vK_tEkMj2v",
        "outputId": "7b6f4463-ac96-456b-f852-1669d32f22fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1,2,3],[4,5,6]])\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf9Psh6IMlUH",
        "outputId": "ede30063-af2d-4dfc-fa46-72fb262ec6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.dtype # int datatype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK5xiyrTNWkR",
        "outputId": "a8408f69-3396-4cfd-c3e0-226c620b8468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. `torch.from_numpy(np_array)` Creating Tensor from Numpy Array\n",
        "    - torch has the `from_numpy()` function which lets us convert Numpy array directly into Tensor.\n",
        "    - can also call `.tensor` on numpy array, but that would create a copy in memory.\n",
        "    - using from_numpy() function it will use the same memory as the numpy array.\n",
        "    - since python uses 64bit precision bydefault, the converted tensor from numpy will be the same 64bit.\n"
      ],
      "metadata": {
        "id": "TM6UDSv7itqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "gQ-vp6CLNYfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array([1., 2., 3.]) # creating numpy array\n",
        "print(f\"Numpy array: {np_array}\")\n",
        "m2 = torch.from_numpy(np_array) # creating tensor from numpy array, its dtype will be same as numpy's that is 64bit,\n",
        "# its 64 because its default type in numpy\n",
        "m2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojOeSKupsC4W",
        "outputId": "4668a333-d422-423d-8296-6e0f171e363e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy array: [1. 2. 3.]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. `tensor_obj.to(new_dtype)` Change the dtype"
      ],
      "metadata": {
        "id": "CgV57S2Ws1Oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m2 # currently its float64 dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfrOD4oTsbyD",
        "outputId": "d02b4bae-29c3-4de3-f9ba-e3aa5f3f6e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m2 = m2.to(torch.float32) # changing 64bit datatype to 32\n",
        "m2.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyODemU2s7oI",
        "outputId": "08f0d44c-f8ea-4b65-b2e0-eaf16f0e97f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. `.device` Checking the device Type\n",
        "    - tensors also have a `.device` attribute, that show us where on our computer the tensor is located.\n",
        "    - So usually it will return CPU which means tensor is on CPU's memory.\n",
        "    - Later will see how to transfer tensors to the GPU which can be very useful for deep learnig and accelerating training."
      ],
      "metadata": {
        "id": "lc5vsaADxaFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m2.device # currently its on cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFQKLt5NwPoS",
        "outputId": "21a3afbb-f636-4ca1-c54f-181baf21498b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Changing Shape of a Tensor\n"
      ],
      "metadata": {
        "id": "2cy2M0q2yppA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.shape)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VENnmoXnyjCY",
        "outputId": "46b2c90a-e049-4a39-e2bc-66ec30b5280e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.view(3,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0GzDL3fy75U",
        "outputId": "998cb0e5-bd5f-4bcb-dc32-098dd0a610c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.view(-1,3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71Qr_WvezIig",
        "outputId": "5b891b89-e9bc-45ff-c219-17438240558c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Transposing a Matrix\n"
      ],
      "metadata": {
        "id": "KYzj6uLa6ZtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LjVrMtszsXm",
        "outputId": "dcdef2a5-2ef5-4a3a-e73f-32fd471c80c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emOoCXfK6e6G",
        "outputId": "83451c76-e7cd-4edd-a761-076f2166d75e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 4.],\n",
              "        [2., 5.],\n",
              "        [3., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kQOM_D7J6noc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}